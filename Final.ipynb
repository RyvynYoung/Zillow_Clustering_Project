{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zillow Clustering Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "**Executive Summary**     \n",
    "**Data Pipeline Overview**     \n",
    "**Exploration Key Insights**     \n",
    "**Modeling Summary**     \n",
    "**Conclusions and Next Steps**     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zestimate Error Drivers**\n",
    "\n",
    "\n",
    "\n",
    "**Best Performing Model**\n",
    "\n",
    "\n",
    "\n",
    "**Conclusions**\n",
    "\n",
    "\n",
    "\n",
    "**Next Steps**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Finish the mvp workflow and then go back and think critically about what you might of missed. The point isn't to doubt yourself; the purpose here is to check your blind spots and see if you can't find more information or insights that will help you to deliver better results.\n",
    "\n",
    "Better yet, and this cannot be stressed enough, don't ask yourself these questions, but bring them up in conversation with peers, experts in other fields, or even complete strangers -- anyone with a different point of view is going to be able to help you to see what things you are taking for granted</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description: \n",
    "- Zillow: What is driving the errors in the Zestimates?\n",
    "- The presentation will consist of a notebook demo of the discoveries you made and work you have done related to uncovering what the drivers of the error in the zestimate is.\n",
    "\n",
    "\n",
    "## Problem Statement\n",
    "- What is driving the error in the Zestimate (logerror)?\n",
    "- Are there features that will produce a smaller average error?\n",
    "- What groups are in the data?\n",
    "- Does using these groups help remove the noise in the model?\n",
    "\n",
    "#### Domain Research\n",
    "- What is a single unit housing unit?\n",
    "    - https://www.investopedia.com/terms/h/housingunits.asp\n",
    "- What is fips?\n",
    "    - https://en.wikipedia.org/wiki/FIPS_county_code\n",
    "- What is the min/max tax rate by county in US?\n",
    "    - https://www.attomdata.com/news/market-trends/figuresfriday/top-10-u-s-counties-with-the-greatest-effective-tax-rates/\n",
    "- Understanding Zillow Zestimate\n",
    "    - https://www.zillow.com/zestimate/\n",
    "    - https://www.youtube.com/watch?v=rfWzMI_VwTQ\n",
    "    - https://www.kaggle.com/c/zillow-prize-1/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**MVP Questions to answer:**\n",
    "- Use clustering to identify new features\n",
    "- Determine the baseline logerror\n",
    "- Produce a model that has less logerror than baseline\n",
    "- Determine key drivers of error\n",
    "\n",
    "**Brainstorm:**    \n",
    "- MVP all counties\n",
    "- features to add:\n",
    "    - county name column, remove fips, get dummies for clustering use\n",
    "    - combined bedroom/bathroom ratio? drop bathroom, keep bedroom\n",
    "    - cluster on size with lot size, finished sq ft, and ????\n",
    "    - convert year build to age (current date - yearbuilt)\n",
    "    - does age correlate with size? if so maybe cluster age with size columns above\n",
    "    - cluster on tax value? taxamount, taxvaluedollarcnt, landtaxvaluedollarcnt, structuretaxvaluedollarcnt?\n",
    "- 2nd run add tax percent rate column and remove outliers above 6.6% and below 1% \n",
    "    - first outlier method removed too many observations, this was done instead\n",
    "    \n",
    "- 2nd run through seperate models by county?\n",
    "\n",
    "\n",
    "Audience: Zillow Data Science Team    \n",
    "Setting: Professional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquire\n",
    "DELIVERABLES: \n",
    "- Data is collected from the Codeup cloud database with an appropriate SQL query\n",
    "- Define single unit property\n",
    "\n",
    "Summary of query requirements and creation:\n",
    "- get all single unit properties, all tables and values from Codeup Zillow database with a transaction date in 2017, but only the most recent transaction date in 2017 and only for those with latitude and longitude\n",
    "\n",
    "**Initial Takeaways**\n",
    "1. could fireplace, garage, pool, hottub, deck be made to 0 or 1 then summed as \"plus_item\" column?\n",
    "    - this would assume null values do not have the feature, as opposed to feature is present but not noted\n",
    "2. drop features with 70% or more missing values to start?\n",
    "3. most rows have 32-34 columns with missing values\n",
    "4. need to define \"single housing unit\" and add that to the filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "Defining single housing unit   \n",
    "\n",
    "**This is deffinition used in previous project**   \n",
    "\n",
    "\"The term housing unit refers to a single unit within a larger structure that can be used by an individual or household to eat, sleep, and live. The unit can be in any type of residence such as a house, apartment, mobile home, or may also be a single unit in a group of rooms.\"\n",
    "https://www.investopedia.com/terms/h/housingunits.asp   \n",
    "\n",
    "**In my opinion deffinition should include condo, townhouse, any unit that can be sold to an individual owner. So my deffinition will include townhouse, condo, ect. but not commercial, business, land only, etc.**   \n",
    "\n",
    "This site has the property use codes for LA county https://www.titleadvantage.com/mdocs/LA%20County%20Use%20Codes%20nm.pdf   \n",
    "looking at the common use codes for Duplex, Triplex, and Quadplex these codes indicate the units are multi-family/income properties or retail/store properties so these will be excluded\n",
    "\n",
    "Identify Properties in the Database: Based on the above definition some categories do not fit brief   \n",
    "Propertylandusetypeid | propertylandusedesc    \n",
    "No 31 Commercial/Office/Residential Mixed Used (not a residence)    \n",
    "No 46 Multi-Story Store (not a residence)   \n",
    "No 47 Store/Office (Mixed Use) (not a residence)    \n",
    "No 246 Duplex (2 Units, Any Combination)    \n",
    "No 247 Triplex (3 Units, Any Combination)   \n",
    "No 248 Quadruplex (4 Units, Any Combination)   \n",
    "260 Residential General    \n",
    "261 Single Family Residential   \n",
    "262 Rural Residence   \n",
    "263 Mobile Home   \n",
    "264 Townhouse   \n",
    "No 265 Cluster Home    \n",
    "266 Condominium    \n",
    "No 267 Cooperative (become shareholder not owner)   \n",
    "268 Row House       \n",
    "No 269 Planned Unit Development   \n",
    "No 270 Residential Common Area (propterty feature)    \n",
    "No 271 Timeshare (become shareholder not owner)    \n",
    "273 Bungalow      \n",
    "274 Zero Lot Line   \n",
    "275 Manufactured, Modular, Prefabricated Homes   \n",
    "276 Patio Home    \n",
    "279 Inferred Single Family Residential      \n",
    "No 290 Vacant Land - General (not a residence)   \n",
    "No 291 Residential Vacant Land (not a residence)   \n",
    "\n",
    "So we will keep only those where propertylandusetypeid = ('260', '261', '262', '263', '264', '266', '268', '273', '274', '275', '276', '279')  \n",
    "\n",
    "**acquire function updated to filter only for these**\n",
    "new shape = (71789, 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acquire data shape= (71789, 70)\n",
      "prepare data shape= (62291, 30)\n",
      "(34882, 22) (14950, 22) (12459, 22)\n",
      "(34882, 19) (14950, 19) (12459, 19)\n"
     ]
    }
   ],
   "source": [
    "import wrangle_zillow\n",
    "\n",
    "df, X_train, y_train, X_validate, y_validate, X_test, y_test,\\\n",
    "X_train_scaled, X_validate_scaled, X_test_scaled, X_train_exp = wrangle_zillow.wrangle_zillow_cluster()\n",
    "# prints shape of X and X scaled dataframess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "DELIVERABLES:\n",
    "- Column data types are appropriate for the data they contain\n",
    "- Missing values are investigated and handled\n",
    "- Outliers are investigated and handled\n",
    "\n",
    "Summary of handling nulls, outliers, creating additional features, dropping columns/rows:\n",
    "1. remove unnecessary duplicated id and tdate columns\n",
    "2. drop rows and columns that are missing more than 50% of values\n",
    "3. add a county name column and get dummies for counties\n",
    "4. remove duplicate columns and those with too many nulls for useful info(heatingsystemtypeid, buildingqualitytypeid, calculatedbathnbr,etc.\n",
    "5. fill remaining nulls in unitcnt with 1 (all units must be minimum of 1 unit)\n",
    "6. initially calculated outliers based on IQR (see next 2 cells)\n",
    "    - decided this eliminated too much data so switch to removing outliers with a tax rate above 6.6% or below 1% based on domain research\n",
    "    - based on explore visualizations of calculated finished sqft and lot size sqft also removed finished sqft above 7000 and lotsize above 2,000,000\n",
    "7. added features: age, tax rate, bed/bath ratio, structure dollars/sqft, land dollars/sqft\n",
    "8. dropped remaining null values (lot size and land dollars were largest remaining colums with 7663 each)\n",
    "9. split dataset into X and y versions of train, validate, test\n",
    "10. drop duplicate value columns not needed for explore or modeling\n",
    "11. created scaled datasets for X train, X validate, and X test\n",
    "12. create X explore dataset with target added back in for exploration and hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MVP - used taxamount to determine cutoff for outliers    \n",
    "for 2nd round might add calculated tax rate column and use that for cut off instead.  \n",
    "**Upperbound Outliers to HANDLE**   \n",
    "\n",
    "**taxamount_outliers**     \n",
    "count      4894.000000     \n",
    "mean      10979.609790     \n",
    "std       20235.975915     \n",
    "min           0.830000     \n",
    "25%        1997.677500     \n",
    "50%        5367.625000     \n",
    "75%       12289.405000     \n",
    "max      573508.600000     \n",
    "Name: taxamount_outliers, dtype: float64     \n",
    "    \n",
    "*******\n",
    "**based on the above info drop upperbound outliers that are above 50th percentile of upperbound outliers**\n",
    "\n",
    "reasoning: there is a significant jump from the 25th to 50th percentile making this a logical place to start removing outliers while still keeping some outliers above the upperbound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lowerbound Outliers to HANDLE**\n",
    "\n",
    "**taxamount_outliers**     \n",
    "count    68981.000000    \n",
    "mean      8203.408061    \n",
    "std       3350.880803    \n",
    "min       3210.485000    \n",
    "25%       5817.075000    \n",
    "50%       7473.745000    \n",
    "75%       9695.125000    \n",
    "max      21685.205000    \n",
    "Name: taxamount_low_outliers, dtype: float64                  \n",
    "   \n",
    "*******\n",
    "**based on the above drop rows that are above the 75th lowerbound percentile**\n",
    "\n",
    "reasoning: there is a significant jump from the 50th to 75th percentile making this a logical place to start removing outliers while still keeping some outliers above the lowerbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62291, 30)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 62291 entries, 0 to 71788\n",
      "Data columns (total 30 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   parcelid                      62291 non-null  int64  \n",
      " 1   bathroomcnt                   62291 non-null  float64\n",
      " 2   bedroomcnt                    62291 non-null  float64\n",
      " 3   calculatedfinishedsquarefeet  62291 non-null  float64\n",
      " 4   fips                          62291 non-null  float64\n",
      " 5   fullbathcnt                   62291 non-null  float64\n",
      " 6   latitude                      62291 non-null  float64\n",
      " 7   longitude                     62291 non-null  float64\n",
      " 8   lotsizesquarefeet             62291 non-null  float64\n",
      " 9   rawcensustractandblock        62291 non-null  float64\n",
      " 10  regionidcounty                62291 non-null  float64\n",
      " 11  regionidzip                   62291 non-null  float64\n",
      " 12  roomcnt                       62291 non-null  float64\n",
      " 13  unitcnt                       62291 non-null  float64\n",
      " 14  yearbuilt                     62291 non-null  float64\n",
      " 15  structuretaxvaluedollarcnt    62291 non-null  float64\n",
      " 16  taxvaluedollarcnt             62291 non-null  float64\n",
      " 17  landtaxvaluedollarcnt         62291 non-null  float64\n",
      " 18  taxamount                     62291 non-null  float64\n",
      " 19  logerror                      62291 non-null  float64\n",
      " 20  propertylandusedesc           62291 non-null  object \n",
      " 21  county                        62291 non-null  object \n",
      " 22  LA                            62291 non-null  uint8  \n",
      " 23  Orange                        62291 non-null  uint8  \n",
      " 24  Ventura                       62291 non-null  uint8  \n",
      " 25  age                           62291 non-null  float64\n",
      " 26  taxrate                       62291 non-null  float64\n",
      " 27  structure_dollar_per_sqft     62291 non-null  float64\n",
      " 28  land_dollar_per_sqft          62291 non-null  float64\n",
      " 29  bed_bath_ratio                62291 non-null  float64\n",
      "dtypes: float64(24), int64(1), object(2), uint8(3)\n",
      "memory usage: 13.5+ MB\n",
      "None\n",
      "           parcelid   bathroomcnt    bedroomcnt  calculatedfinishedsquarefeet  \\\n",
      "count  6.229100e+04  62291.000000  62291.000000                  62291.000000   \n",
      "mean   1.277832e+07      2.267743      3.088343                   1778.383506   \n",
      "std    2.085661e+06      0.936601      1.000793                    875.087535   \n",
      "min    1.071186e+07      1.000000      0.000000                    152.000000   \n",
      "25%    1.145376e+07      2.000000      2.000000                   1192.000000   \n",
      "50%    1.240969e+07      2.000000      3.000000                   1548.000000   \n",
      "75%    1.399082e+07      3.000000      4.000000                   2126.000000   \n",
      "max    1.629608e+08     10.000000     11.000000                   6995.000000   \n",
      "\n",
      "               fips   fullbathcnt      latitude     longitude  \\\n",
      "count  62291.000000  62291.000000  6.229100e+04  6.229100e+04   \n",
      "mean    6047.461511      2.213257  3.403436e+07 -1.182237e+08   \n",
      "std       20.377877      0.915196  2.595374e+05  3.433905e+05   \n",
      "min     6037.000000      1.000000  3.333953e+07 -1.194753e+08   \n",
      "25%     6037.000000      2.000000  3.384396e+07 -1.184269e+08   \n",
      "50%     6037.000000      2.000000  3.404474e+07 -1.181978e+08   \n",
      "75%     6059.000000      3.000000  3.418511e+07 -1.179695e+08   \n",
      "max     6111.000000     10.000000  3.481877e+07 -1.175546e+08   \n",
      "\n",
      "       lotsizesquarefeet  rawcensustractandblock  ...      taxamount  \\\n",
      "count       6.229100e+04            6.229100e+04  ...   62291.000000   \n",
      "mean        2.957898e+04            6.047792e+07  ...    5916.713835   \n",
      "std         9.323049e+04            2.022485e+05  ...    6440.786237   \n",
      "min         2.360000e+02            6.037101e+07  ...     202.120000   \n",
      "25%         5.885000e+03            6.037300e+07  ...    2661.685000   \n",
      "50%         7.340000e+03            6.037572e+07  ...    4445.350000   \n",
      "75%         1.240750e+04            6.059032e+07  ...    6945.555000   \n",
      "max         1.904165e+06            6.111009e+07  ...  288524.600000   \n",
      "\n",
      "           logerror            LA        Orange       Ventura           age  \\\n",
      "count  62291.000000  62291.000000  62291.000000  62291.000000  62291.000000   \n",
      "mean       0.017281      0.705399      0.218057      0.076544     50.527219   \n",
      "std        0.166512      0.455867      0.412930      0.265869     22.671704   \n",
      "min       -4.655420      0.000000      0.000000      0.000000      1.000000   \n",
      "25%       -0.024354      0.000000      0.000000      0.000000     33.000000   \n",
      "50%        0.006780      1.000000      0.000000      0.000000     52.000000   \n",
      "75%        0.039306      1.000000      0.000000      0.000000     65.000000   \n",
      "max        5.262999      1.000000      1.000000      1.000000    139.000000   \n",
      "\n",
      "            taxrate  structure_dollar_per_sqft  land_dollar_per_sqft  \\\n",
      "count  62291.000000               62291.000000          62291.000000   \n",
      "mean       0.013179                  97.997440             41.977785   \n",
      "std        0.003064                  62.626172             68.379356   \n",
      "min        0.010000                   0.039833              0.004444   \n",
      "25%        0.011776                  60.126579              5.218775   \n",
      "50%        0.012312                  89.540144             23.641713   \n",
      "75%        0.013507                 122.443328             53.222301   \n",
      "max        0.065860                1682.457143           1882.546201   \n",
      "\n",
      "       bed_bath_ratio  \n",
      "count    62291.000000  \n",
      "mean         1.496366  \n",
      "std          0.581184  \n",
      "min          0.000000  \n",
      "25%          1.000000  \n",
      "50%          1.500000  \n",
      "75%          2.000000  \n",
      "max          5.000000  \n",
      "\n",
      "[8 rows x 28 columns]\n",
      "                              num_rows_missing  pct_rows_missing\n",
      "parcelid                                     0               0.0\n",
      "bathroomcnt                                  0               0.0\n",
      "bedroomcnt                                   0               0.0\n",
      "calculatedfinishedsquarefeet                 0               0.0\n",
      "fips                                         0               0.0\n",
      "fullbathcnt                                  0               0.0\n",
      "latitude                                     0               0.0\n",
      "longitude                                    0               0.0\n",
      "lotsizesquarefeet                            0               0.0\n",
      "rawcensustractandblock                       0               0.0\n",
      "regionidcounty                               0               0.0\n",
      "regionidzip                                  0               0.0\n",
      "roomcnt                                      0               0.0\n",
      "unitcnt                                      0               0.0\n",
      "yearbuilt                                    0               0.0\n",
      "structuretaxvaluedollarcnt                   0               0.0\n",
      "taxvaluedollarcnt                            0               0.0\n",
      "landtaxvaluedollarcnt                        0               0.0\n",
      "taxamount                                    0               0.0\n",
      "logerror                                     0               0.0\n",
      "propertylandusedesc                          0               0.0\n",
      "county                                       0               0.0\n",
      "LA                                           0               0.0\n",
      "Orange                                       0               0.0\n",
      "Ventura                                      0               0.0\n",
      "age                                          0               0.0\n",
      "taxrate                                      0               0.0\n",
      "structure_dollar_per_sqft                    0               0.0\n",
      "land_dollar_per_sqft                         0               0.0\n",
      "bed_bath_ratio                               0               0.0\n",
      "   null_count  pct_null  rows_with_count\n",
      "0           0       0.0            62291\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-247018e74b3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfulldf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/codeup-data-science/zillow_clustering_project/summarize.py\u001b[0m in \u001b[0;36mdf_summary\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnulls_by_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mgraphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     41\u001b[0m             display(\n\u001b[1;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</usr/local/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2092\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1709\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;31m# scale up the axis label box to also find the neighbors, not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    295\u001b[0m         for artist in [self.gridline, self.tick1line, self.tick2line,\n\u001b[1;32m    296\u001b[0m                        self.label1, self.label2]:\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dashes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dashOffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dashSeq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw_path\u001b[0;34m(self, gc, path, transform, rgbFace)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgbFace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOverflowError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 raise OverflowError(\"Exceeded cell block limit (set \"\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mget_dashes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dashes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m         \"\"\"\n\u001b[1;32m    800\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdash\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0man\u001b[0m \u001b[0moffset\u001b[0m \u001b[0mdashlist\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# During this stage called this summary function to assist in seeing remain nulls to handle and\n",
    "# for histograms of individual variables.\n",
    "# Can be used for full dataframe or any of the split or scaled dataframes\n",
    "import summarize\n",
    "\n",
    "fulldf = summarize.df_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Explore needs cleaned up and funcions created and called. Needs hypothesis testing and county cluster</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "DELIVERABLES:      \n",
    "**- Interaction between independent variables and the target variable is explored using visualization and statistical testing**\n",
    "- Clustering is used to explore the data\n",
    "- A conclusion, supported by statistical testing and visualization, is drawn on whether or not the clusters are helpful/useful\n",
    "- At least 3 combinations of features for clustering should be tried\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import kruskal\n",
    "import explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction between independent and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "columns = X_train_exp.columns\n",
    "for col in columns:\n",
    "    plt.figure(figsize=(13, 7))\n",
    "    sns.scatterplot(data=X_train_exp, x=col, y='logerror', hue='county')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "**Take aways from visualizations**\n",
    "1. room count for LA county appears to be all 0 or 1, so not useful for that county\n",
    "2. unit count should is nearly all 1, so does not add value in any county\n",
    "2. age and calculated sqft have a wide spread in error\n",
    "3. lot size has a wide spread in error for small size lots, may need to not use this feature?\n",
    "4. Orange county appears to have largest spread in logerror: 2 possible factors not in dataset\n",
    "    - perceived value of properties due to \"wealth\" of county\n",
    "    - perceived value based public school rankings\n",
    "\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing with target variable\n",
    "\n",
    "Is the average logerror significantly different by county?     \n",
    "Ho: The logerror is not significantly different for properties in LA vs Orange vs Ventura counties    \n",
    "Ha: The logerro is significantly different      \n",
    "    \n",
    "We will check the variances with a levene test to see if the ANOVA or Kruskal test should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('mean LA logerror =', X_train_exp[X_train_exp.county == \"LA\"].logerror.mean())\n",
    "print('mean Orange logerror=', X_train_exp[X_train_exp.county == \"Orange\"].logerror.mean())\n",
    "print('mean Ventura logerror=', X_train_exp[X_train_exp.county == \"Ventura\"].logerror.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .05\n",
    "\n",
    "LA = X_train_exp[X_train_exp.county == \"LA\"].logerror\n",
    "Orange = X_train_exp[X_train_exp.county == \"Orange\"].logerror\n",
    "Ventura = X_train_exp[X_train_exp.county == \"Ventura\"].logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.levene(LA, Orange, Ventura)\n",
    "# with a p value < .05 the variances are not similar enough for the ANOVA test\n",
    "# will use scipy.stats.kruskal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kruskal(LA, Orange, Ventura)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take Aways**     \n",
    "\n",
    "Kruskal test the pvalue is < .05 so we would reject the Ho and conclude that there is a significant difference in logerror by county      \n",
    "\n",
    "NOTE: this just shows 1 or more are different but does not indicate that all 3 are significantly different from each other, 2 may be same\n",
    "\n",
    "Is the difference in average log error between LA and Orange county significant?     \n",
    "Ho: There is no significant difference in the average logerror between LA and Orange counties      \n",
    "Ha: There is a significant difference in the average logerror between LA and Orange counties      \n",
    "\n",
    "For this we will use a two sample, two tailed t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.levene(LA, Orange))\n",
    "print(stats.levene(LA, Ventura))\n",
    "print(stats.levene(Ventura, Orange))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(LA, Orange, equal_var=False)\n",
    "print(\"p = \", p)\n",
    "print(\"t = \", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take Away**     \n",
    "The p is less than alpha so we reject the null hypothesis and conclude that there is a signficant difference between the mean logerror of LA and Orange counties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the difference in average log error between LA and Ventura county significant?     \n",
    "Ho: There is no significant difference in the average logerror between LA and Ventura counties      \n",
    "Ha: There is a significant difference in the average logerror between LA and Ventura counties   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(LA, Ventura, equal_var=False)\n",
    "print(\"p = \", p)\n",
    "print(\"t = \", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take Away**     \n",
    "The p is greater than alpha so we fail to reject the null hypothesis and conclude that there is not a signficant difference between the mean logerror of LA and Ventura counties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the difference in average log error between Ventura and Orange county significant?     \n",
    "Ho: There is no significant difference in the average logerror between Ventura and Orange counties      \n",
    "Ha: There is a significant difference in the average logerror between Ventura and Orange counties   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p = stats.ttest_ind(Ventura, Orange, equal_var=True)\n",
    "print(\"p = \", p)\n",
    "print(\"t = \", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p is greater than alpha so we fail to reject the null hypothesis and conclude that there is not a signficant difference between the mean logerror of Ventura and Orange counties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a significant relationship between calculatedfinishedsquarefeet and logerror?      \n",
    "Ho: There is no relationship between logerror and calculated finished sq ft      \n",
    "Ha: There is a relationship between logerror and calculated finished sq ft  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_var1 = X_train_exp.calculatedfinishedsquarefeet\n",
    "continuous_var2 = X_train_exp.logerror\n",
    "r, p = explore.pearson(continuous_var1, continuous_var2)\n",
    "\n",
    "r, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take Away**     \n",
    "The p is less than alpha so we reject the null hypothesis and conclude that there is a relationship between  ogerror and calculated finished sq ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a significant relationship between age and logerror?      \n",
    "Ho: There is no relationship between logerror and age      \n",
    "Ha: There is a relationship between logerror and age  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_var1 = X_train_exp.age\n",
    "continuous_var2 = X_train_exp.logerror\n",
    "r, p = explore.pearson(continuous_var1, continuous_var2)\n",
    "\n",
    "r, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take Away**     \n",
    "The p is less than alpha so we reject the null hypothesis and conclude that there is a relationship between  ogerror and age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_exp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars2test = ['bedroomcnt', 'calculatedfinishedsquarefeet', 'fullbathcnt', 'lotsizesquarefeet', 'roomcnt', \n",
    "             'unitcnt', 'structuretaxvaluedollarcnt', 'taxvaluedollarcnt', 'taxamount', 'LA', 'Orange', \n",
    "             'Ventura', 'age', 'taxrate', 'structure_dollar_per_sqft', 'land_dollar_per_sqft', 'bed_bath_ratio']\n",
    "r_value = []\n",
    "p_value = []\n",
    "continuous_var2 = X_train_exp.logerror\n",
    "for i in vars2test:\n",
    "    continuous_var1 = X_train_exp[i]\n",
    "    r, p = explore.pearson(continuous_var1, continuous_var2)\n",
    "    r_value.append(r)\n",
    "    p_value.append(p)\n",
    "\n",
    "\n",
    "stats_list = ['bedroomcnt', 'calculatedfinishedsquarefeet', 'fullbathcnt', 'lotsizesquarefeet', 'roomcnt', \n",
    "             'unitcnt', 'structuretaxvaluedollarcnt', 'taxvaluedollarcnt', 'taxamount', 'LA', 'Orange', \n",
    "             'Ventura', 'age', 'taxrate', 'structure_dollar_per_sqft', 'land_dollar_per_sqft', 'bed_bath_ratio']\n",
    "\n",
    "null_list = []\n",
    "for p in p_value:\n",
    "    if p < .05:\n",
    "        null_list.append('reject Ho')\n",
    "    else:\n",
    "        null_list.append('fail to reject Ho')\n",
    "        \n",
    "stat_res = pd.DataFrame(stats_list, columns=['Feature'])\n",
    "stat_res['r_value'] = r_value\n",
    "stat_res['p_value'] = p_value\n",
    "stat_res['hypothesis'] = null_list\n",
    "stat_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take aways**      \n",
    "Based on these results the following should be drivers of logerror:\n",
    "    - bedroomcnt, calculatedfinishedsquarefeet, fullbathcnt, roomcnt, taxvaluedollarcnt, taxamount, LA, Orange, age, taxrate, structure_dollar_per_sqft, land_dollar_per_sqft "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 1 = size_cluster\n",
    "##### Does age correlate with size?\n",
    "1. decided to use calculatedfinishedsquarefeet for size to answer this\n",
    "2. visualize age and size together (both continuous variables)\n",
    "3. use scatter plot for chart\n",
    "4. use stats.pearsonr for hypothesis testing\n",
    "\n",
    "##### Hypothesis test\n",
    "Ho: There is no relationship between age and size.     \n",
    "Ha: There is a relationship between age and size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize relationship between age and size\n",
    "plt.figure(figsize=(16, 9))\n",
    "sns.scatterplot(data=X_train_exp, y='calculatedfinishedsquarefeet', x='age', hue='county', alpha=.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this visual it may be better to separate by county and retest in next iteratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_var1 = X_train.age\n",
    "continuous_var2 = X_train.calculatedfinishedsquarefeet\n",
    "r, p = explore.pearson(continuous_var1, continuous_var2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is less than alpha so we reject the null hypothesis, though the r value is not far from zero and is negative, which would indicate a weak negative linear correlation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take away**      \n",
    "Based on correlation of age and size (though weak) will try clustering on calculatedfinishedsquarefeet, lotsizesquarefeet, and age.    \n",
    "This produced a very slight improvement over baseline. Removing age from this cluster to see impact.     \n",
    "No effect when age removed from this cluster, so leaving it out of this cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_vars = ['calculatedfinishedsquarefeet_scaled', 'lotsizesquarefeet_scaled']\n",
    "explore.elbow_plot(X_train_scaled, cluster_vars)\n",
    "# based on this will use 6 as k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set K value, get clusters and view dispersal\n",
    "k=6\n",
    "cluster_col_name = 'size_cluster'\n",
    "train_clusters, kmeans = explore.run_kmeans(X_train_scaled, X_train, cluster_vars, k, cluster_col_name)\n",
    "train_clusters.size_cluster.value_counts()\n",
    "# so so dispersal of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the centroids and add all to train and scaled datasets\n",
    "centroids = explore.get_centroids(kmeans, cluster_vars, cluster_col_name)\n",
    "X_train, X_train_scaled = explore.add_to_train(X_train, train_clusters, X_train_scaled, centroids, cluster_col_name)\n",
    "val_trans_clusters = explore.kmeans_transform(X_validate_scaled, kmeans, cluster_vars, cluster_col_name)\n",
    "test_trans_clusters = explore.kmeans_transform(X_test_scaled, kmeans, cluster_vars, cluster_col_name)\n",
    "X_validate, X_validate_scaled = explore.add_to_train(X_validate, val_trans_clusters, X_validate_scaled, centroids, cluster_col_name)\n",
    "X_test, X_test_scaled = explore.add_to_train(X_test, test_trans_clusters, X_test_scaled, centroids, cluster_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(13, 7))\n",
    "\n",
    "for cluster, subset in X_train_scaled.groupby('size_cluster'):\n",
    "    ax.scatter(subset.calculatedfinishedsquarefeet_scaled, subset.lotsizesquarefeet_scaled, label=cluster)\n",
    "ax.legend(title='size_cluster')\n",
    "ax.set(ylabel='lotsizesquarefeet_scaled', xlabel='calculatedfinishedsquarefeet_scaled')\n",
    "\n",
    "X_train_scaled.groupby('size_cluster').mean().plot.scatter(y='lotsizesquarefeet_scaled', x='calculatedfinishedsquarefeet_scaled', marker='x', s=1000, ax=ax, c='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 2 = dollar_cluster     \n",
    "\n",
    "Will combining all dollar amount features be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction of structuretaxvaluedollarcnt and taxvaluedollarcnt with target?\n",
    "plt.figure(figsize=(16, 9))\n",
    "sns.scatterplot(data=X_train_exp, x='structuretaxvaluedollarcnt', y='taxvaluedollarcnt', hue='logerror', alpha=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use structuretaxvaluedollarcnt, taxvaluedollarcnt, taxamount, structure_dollar_per_sqft, land_dollar_per_sqft, taxrate\n",
    "cluster_vars2 = ['structuretaxvaluedollarcnt_scaled', 'taxvaluedollarcnt_scaled', 'taxamount_scaled','structure_dollar_per_sqft_scaled', 'land_dollar_per_sqft_scaled', 'taxrate_scaled']\n",
    "explore.elbow_plot(X_train_scaled, cluster_vars2)\n",
    "# based on this will use 5 as k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set K value, get clusters and view dispersal\n",
    "k2=5\n",
    "cluster_col_name2 = 'dollar_cluster'\n",
    "train_clusters2, kmeans2 = explore.run_kmeans(X_train_scaled, X_train, cluster_vars2, k2, cluster_col_name2)\n",
    "train_clusters2.dollar_cluster.value_counts()\n",
    "# based on this distribution this clustering may not be that helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the centroids and add all to train and scaled datasets\n",
    "centroids2 = explore.get_centroids(kmeans2, cluster_vars2, cluster_col_name2)\n",
    "X_train, X_train_scaled = explore.add_to_train(X_train, train_clusters2, X_train_scaled, centroids2, cluster_col_name2)\n",
    "val_trans_clusters2 = explore.kmeans_transform(X_validate_scaled, kmeans2, cluster_vars2, cluster_col_name2)\n",
    "test_trans_clusters2 = explore.kmeans_transform(X_test_scaled, kmeans2, cluster_vars2, cluster_col_name2)\n",
    "X_validate, X_validate_scaled = explore.add_to_train(X_validate, val_trans_clusters2, X_validate_scaled, centroids2, cluster_col_name2)\n",
    "X_test, X_test_scaled = explore.add_to_train(X_test, test_trans_clusters2, X_test_scaled, centroids2, cluster_col_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the clusters\n",
    "sns.relplot(x=\"structuretaxvaluedollarcnt_scaled\", y=\"taxvaluedollarcnt_scaled\", hue=\"taxamount_scaled\", col=\"dollar_cluster\", col_wrap=2, data=X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 3 = rooms cluster\n",
    "\n",
    "##### Does bed/bath ratio correlate with age?\n",
    "1. visualize bed_bath_ratio and age together (both continuous variables)\n",
    "2. use scatter plot for chart\n",
    "3. based on chart bin bed_bath ratio and age and visualize\n",
    "4. use chi squared test to compare \n",
    "\n",
    "##### Hypothesis test\n",
    "Ho: Bed_bath_ratio and age are independent.     \n",
    "Ha: Bed_bath_ratio and age are dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between bed/bath ratio with age to see if any relationship\n",
    "plt.figure(figsize=(16, 9))\n",
    "sns.scatterplot(data=X_train, y='age', x='bed_bath_ratio', hue='county', alpha=.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this visualization maybe binning these features would work better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binned bed_bath_ratio column\n",
    "X_train['bb_bin'] = pd.cut(X_train.bed_bath_ratio, bins=[0, 1, 2, 3, 4], labels=['1', '2', '3', '4+'])\n",
    "# create binned age column by 20 yr groups\n",
    "X_train['age_bin'] = pd.cut(X_train.age, bins=[0, 20, 40, 60, 80], labels=['<20', '40', '60', '80+'])\n",
    "# visualize these 2 categorical variables together\n",
    "# Heatmap of bined values (Categorical and Categorical)\n",
    "plt.figure(figsize=(16,9))\n",
    "ctab = pd.crosstab(X_train.bb_bin, X_train.age_bin, normalize=True)\n",
    "sns.heatmap(ctab, cmap='Purples', annot=True, fmt='.1%')\n",
    "plt.title('What is correlation between bined bed/bath ratio and binned age of home?')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis Test\n",
    "categorical_var1 = X_train.bb_bin\n",
    "categorical_var2 = X_train.age_bin\n",
    "p = explore.chi2test(categorical_var1, categorical_var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create rooms cluster\n",
    "# use bedroomcnt, fullbathcnt, roomcnt, structure_dollar_per_sqft, land_dollar_per_sqft, taxrate\n",
    "cluster_vars3 = ['bedroomcnt_scaled', 'fullbathcnt_scaled', 'roomcnt_scaled', 'bed_bath_ratio_scaled']\n",
    "explore.elbow_plot(X_train_scaled, cluster_vars3)\n",
    "# based on this will use 6 as k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set K value, get clusters and view dispersal\n",
    "k3=6\n",
    "cluster_col_name3 = 'rooms_cluster'\n",
    "train_clusters3, kmeans3 = explore.run_kmeans(X_train_scaled, X_train, cluster_vars3, k3, cluster_col_name3)\n",
    "train_clusters3.rooms_cluster.value_counts()\n",
    "# pretty good dispersal of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the centroids and add all to train and scaled datasets\n",
    "centroids3 = explore.get_centroids(kmeans3, cluster_vars3, cluster_col_name3)\n",
    "val_trans_clusters3 = explore.kmeans_transform(X_validate_scaled, kmeans3, cluster_vars3, cluster_col_name3)\n",
    "test_trans_clusters3 = explore.kmeans_transform(X_test_scaled, kmeans3, cluster_vars3, cluster_col_name3)\n",
    "X_train, X_train_scaled = explore.add_to_train(X_train, train_clusters3, X_train_scaled, centroids3, cluster_col_name3)\n",
    "X_validate, X_validate_scaled = explore.add_to_train(X_validate, val_trans_clusters3, X_validate_scaled, centroids3, cluster_col_name3)\n",
    "X_test, X_test_scaled = explore.add_to_train(X_test, test_trans_clusters3, X_test_scaled, centroids3, cluster_col_name3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"bed_bath_ratio_scaled\", y=\"bedroomcnt_scaled\", col=\"rooms_cluster\", col_wrap=2, data=X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 4 = location_cluster     \n",
    "\n",
    "2nd iteration: add area/location cluster with longitude, latitude, encoded counties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use longitude, latitude, ages\n",
    "cluster_vars4 = ['longitude_scaled', 'latitude_scaled', 'age_scaled']\n",
    "explore.elbow_plot(X_train_scaled, cluster_vars4)\n",
    "# based on this will use 6 as k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set K value, get clusters and view dispersal\n",
    "k4=6\n",
    "cluster_col_name4 = 'loc_cluster'\n",
    "train_clusters4, kmeans4 = explore.run_kmeans(X_train_scaled, X_train, cluster_vars4, k4, cluster_col_name4)\n",
    "train_clusters4.loc_cluster.value_counts()\n",
    "# good dispersal of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the centroids and add all to train and scaled datasets\n",
    "centroids4 = explore.get_centroids(kmeans4, cluster_vars4, cluster_col_name4)\n",
    "X_train, X_train_scaled = explore.add_to_train(X_train, train_clusters4, X_train_scaled, centroids4, cluster_col_name4)\n",
    "val_trans_clusters4 = explore.kmeans_transform(X_validate_scaled, kmeans4, cluster_vars4, cluster_col_name4)\n",
    "test_trans_clusters4 = explore.kmeans_transform(X_test_scaled, kmeans4, cluster_vars4, cluster_col_name4)\n",
    "X_validate, X_validate_scaled = explore.add_to_train(X_validate, val_trans_clusters4, X_validate_scaled, centroids4, cluster_col_name4)\n",
    "X_test, X_test_scaled = explore.add_to_train(X_test, test_trans_clusters4, X_test_scaled, centroids4, cluster_col_name4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize clusters\n",
    "fig, ax = plt.subplots(figsize=(13, 7))\n",
    "\n",
    "for cluster, subset in X_train_scaled.groupby('loc_cluster'):\n",
    "    ax.scatter(subset.longitude_scaled, subset.latitude_scaled, subset.age_scaled, label=cluster)\n",
    "ax.legend(title='loc_cluster')\n",
    "ax.set(ylabel='latitude_scaled', xlabel='longitude_scaled')\n",
    "\n",
    "X_train_scaled.groupby('loc_cluster').mean().plot.scatter(y='latitude_scaled', x='longitude_scaled', marker='x', s=1000, ax=ax, c='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Stage\n",
    "DELIVERABLES: \n",
    "- At least 4 different models are created and their performance is compared\n",
    "- One model is the distinct combination of algorithm, hyperparameters, and features\n",
    "- Best practices on data splitting are followed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import model\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, RFE \n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from math import sqrt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try finding best ranking features and limiting features to top 2 or 5?\n",
    "lm = LinearRegression()\n",
    "rfe = RFE(lm, 1)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "ranks = rfe.ranking_\n",
    "names = X_train_scaled.columns.tolist()\n",
    "pd.DataFrame({'features': names, 'rank': ranks}).set_index('rank').sort_values('rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "**features takeaway**     \n",
    "- each county is top 3, will do a model with just those 3\n",
    "- next features are related to Dollar cluster so will do county with dollar centriods\n",
    "- then size, then rooms so county with each of those\n",
    "- one with no centroids\n",
    "- one with only centroids\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare stats results of drivers to features rank:**          \n",
    "bedroomcnt(20), calculatedfinishedsquarefeet(36), fullbathcnt(16), roomcnt(18), taxvaluedollarcnt(11), taxamount(10), LA(3), Orange (1), age(32), taxrate(13), structure_dollar_per_sqft(12), land_dollar_per_sqft(17)    \n",
    "\n",
    "Did not have a chance to build anonther model based on this info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all based on X_train_scaled\n",
    "Xtrains_ALL = X_train_scaled.copy().drop(columns=['size_cluster', 'rooms_cluster', 'dollar_cluster', \n",
    "                                                  'loc_cluster'])\n",
    "\n",
    "Xtrains_noClusters = X_train_scaled[['LA', 'Orange', 'Ventura', 'bedroomcnt_scaled',\n",
    "       'calculatedfinishedsquarefeet_scaled', 'fullbathcnt_scaled',\n",
    "       'lotsizesquarefeet_scaled', 'roomcnt_scaled', 'unitcnt_scaled',\n",
    "       'structuretaxvaluedollarcnt_scaled', 'taxvaluedollarcnt_scaled',\n",
    "       'taxamount_scaled', 'longitude_scaled', 'latitude_scaled', 'age_scaled',\n",
    "       'taxrate_scaled', 'structure_dollar_per_sqft_scaled',\n",
    "       'land_dollar_per_sqft_scaled', 'bed_bath_ratio_scaled']]\n",
    "\n",
    "Xtrains_only_county = X_train_scaled[['LA', 'Orange', 'Ventura']]\n",
    "\n",
    "Xtrains_onlyLoc = X_train_scaled[['centroid_longitude_scaled', 'centroid_latitude_scaled',\n",
    "       'centroid_age_scaled']]\n",
    "\n",
    "Xtrains_onlyCentroids = X_train_scaled[['centroid_calculatedfinishedsquarefeet_scaled',\n",
    "       'centroid_lotsizesquarefeet_scaled', 'centroid_structuretaxvaluedollarcnt_scaled',\n",
    "       'centroid_taxvaluedollarcnt_scaled', 'centroid_taxamount_scaled',\n",
    "       'centroid_structure_dollar_per_sqft_scaled', 'centroid_land_dollar_per_sqft_scaled', \n",
    "        'centroid_taxrate_scaled', 'centroid_bedroomcnt_scaled','centroid_fullbathcnt_scaled', \n",
    "        'centroid_roomcnt_scaled', 'centroid_bed_bath_ratio_scaled', 'loc_cluster',\n",
    "       'centroid_longitude_scaled', 'centroid_latitude_scaled', 'centroid_age_scaled']]\n",
    "\n",
    "Xtrains_countyDollar = X_train_scaled[['LA', 'Orange', 'Ventura','centroid_structuretaxvaluedollarcnt_scaled',\n",
    "       'centroid_taxvaluedollarcnt_scaled', 'centroid_taxamount_scaled',\n",
    "       'centroid_structure_dollar_per_sqft_scaled', 'centroid_land_dollar_per_sqft_scaled', \n",
    "        'centroid_taxrate_scaled']]\n",
    "\n",
    "Xtrains_countySize = X_train_scaled[['LA', 'Orange', 'Ventura', \n",
    "                                     'centroid_calculatedfinishedsquarefeet_scaled',\n",
    "                                     'centroid_lotsizesquarefeet_scaled']]\n",
    "\n",
    "Xtrains_countyRooms = X_train_scaled[['LA', 'Orange', 'Ventura', 'centroid_bedroomcnt_scaled',\n",
    "       'centroid_fullbathcnt_scaled', 'centroid_roomcnt_scaled',\n",
    "       'centroid_bed_bath_ratio_scaled']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models\n",
    "***for MVP these are variations on Linear Regression Model altering features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline, basepred = model.get_baseline(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2test = [Xtrains_ALL, Xtrains_noClusters, Xtrains_only_county, Xtrains_onlyLoc, Xtrains_onlyCentroids, \n",
    "           Xtrains_countyDollar, Xtrains_countySize, Xtrains_countyRooms]\n",
    "target = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Models\n",
    "lm_list = []\n",
    "pred_list = []\n",
    "RMSE_list = []\n",
    "for df in df2test:\n",
    "    lm, pred, RMSE = model.linear_reg_train(df, target)\n",
    "    \n",
    "    pred_list.append(pred)\n",
    "    RMSE_list.append(RMSE)\n",
    "    print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "**Take aways from Linear Regression models**     \n",
    "Model with all features and only clusters performed best. Though not much better than baseline.\n",
    "\n",
    "**Next Step**     \n",
    "- try alternate algorithm\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoLars Models\n",
    "# this produces same result for all dataframes because this model does feature selection within the model and \n",
    "# is selecting the same features from all dataframes\n",
    "for df in df2test:\n",
    "    ll_RMSE = model.lasso_lars(df, target)\n",
    "    print(ll_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "**Take aways from LassoLars models**     \n",
    "All match the baseline. Possibly due to how feature selection works in the algorithm\n",
    "\n",
    "**Next Step**     \n",
    "- try alternate algorithm\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweedie\n",
    "tweedie = []\n",
    "for df in df2test:\n",
    "    tw_RMSE = model.tweedie(df, target)\n",
    "    tweedie.append(tw_RMSE)\n",
    "    print(tw_RMSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "**Take aways from Tweedie models**     \n",
    "These are not an improvement from the Linear Regression models and are very close to baseline in all cases.\n",
    "\n",
    "**Next Step**     \n",
    "- Top 3 linear regression models to validate\n",
    "*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = ['all', 'no clusters', 'only county', 'only location', 'only centriods',\n",
    "           'county with dollar', 'county with size', 'county with rooms']\n",
    "\n",
    "results = pd.DataFrame(df_list, columns=['Features'])\n",
    "results['LinearReg'] = RMSE_list\n",
    "results['Tweedie'] = tweedie\n",
    "results['Baseline'] = baseline\n",
    "results.sort_values('LinearReg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Performing Models**    \n",
    "\n",
    "Linear Regreession with ALL              \n",
    "Linear Regreession with no clustering     \n",
    "Linear Regreession with only centroids       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df for scaled validate\n",
    "Xvals_ALL = X_validate_scaled.copy().drop(columns=['size_cluster', 'rooms_cluster', 'dollar_cluster', \n",
    "                                                  'loc_cluster'])\n",
    "# no clusters\n",
    "Xvals_noClusters = X_validate_scaled[['LA', 'Orange', 'Ventura', 'bedroomcnt_scaled',\n",
    "       'calculatedfinishedsquarefeet_scaled', 'fullbathcnt_scaled',\n",
    "       'lotsizesquarefeet_scaled', 'roomcnt_scaled', 'unitcnt_scaled',\n",
    "       'structuretaxvaluedollarcnt_scaled', 'taxvaluedollarcnt_scaled',\n",
    "       'taxamount_scaled', 'longitude_scaled', 'latitude_scaled', 'age_scaled',\n",
    "       'taxrate_scaled', 'structure_dollar_per_sqft_scaled',\n",
    "       'land_dollar_per_sqft_scaled', 'bed_bath_ratio_scaled']]\n",
    "\n",
    "Xvals_onlyCentroids = X_validate_scaled[['centroid_calculatedfinishedsquarefeet_scaled',\n",
    "       'centroid_lotsizesquarefeet_scaled', 'centroid_structuretaxvaluedollarcnt_scaled',\n",
    "       'centroid_taxvaluedollarcnt_scaled', 'centroid_taxamount_scaled',\n",
    "       'centroid_structure_dollar_per_sqft_scaled', 'centroid_land_dollar_per_sqft_scaled', \n",
    "        'centroid_taxrate_scaled', 'centroid_bedroomcnt_scaled','centroid_fullbathcnt_scaled', \n",
    "        'centroid_roomcnt_scaled', 'centroid_bed_bath_ratio_scaled', 'loc_cluster',\n",
    "       'centroid_longitude_scaled', 'centroid_latitude_scaled', 'centroid_age_scaled']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate with all\n",
    "vall_RMSE, vall_pred = model.linear_reg_vt(Xtrains_ALL, Xvals_ALL, y_train, y_validate)\n",
    "vall_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate with no clusters\n",
    "ncl_RMSE, ncl_pred = model.linear_reg_vt(Xtrains_noClusters, Xvals_noClusters, y_train, y_validate)\n",
    "ncl_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate with only centroids\n",
    "ocent_RMSE, ocent_pred = model.linear_reg_vt(Xtrains_onlyCentroids, Xvals_onlyCentroids, y_train, y_validate)\n",
    "ocent_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.axhline(label=\"No Error\")\n",
    "plt.scatter(y_validate, vall_pred - y_validate,\n",
    "            alpha=.3, color=\"blue\", s=100, label=\"Model: LinearRegression-ALL\")\n",
    "plt.scatter(y_validate, ncl_pred - y_validate, \n",
    "            alpha=.6, color=\"yellow\", s=100, label=\"Model: LinearRegression-no clusters\")\n",
    "plt.scatter(y_validate, ocent_pred - y_validate, \n",
    "            alpha=.1, color=\"purple\", s=100, label=\"Model: LinearRegression-only centroids\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"y_validate\")\n",
    "plt.ylabel(\"Residual/Error: Predicted - Actual\")\n",
    "plt.title(\"Do the size of errors change as the actual value changes?\")\n",
    "plt.xlim(-.75, .75)\n",
    "plt.ylim(-.75, .75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a baseline from train mean that is the same shape as validate\n",
    "rows_needed = y_validate.shape[0]\n",
    "# create array of predictions of same size as y_train.logerror based on the mean\n",
    "vy_hat = np.full(rows_needed, np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs y_validate\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_validate, vy_hat, alpha=.5, color=\"gray\", label='_nolegend_')\n",
    "#plt.annotate(\"Baseline: Predict Using Mean\", (-3, 3))\n",
    "plt.plot(y_validate, y_validate, alpha=.5, color=\"blue\", label='_nolegend_')\n",
    "#plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_validate, vall_pred, \n",
    "            alpha=.5, color=\"red\", s=100, label=\"Model: LinearRegression-ALL\")\n",
    "plt.scatter(y_validate, ncl_pred, \n",
    "            alpha=.6, color=\"yellow\", s=100, label=\"Model: LinearRegression-no clusters\")\n",
    "plt.scatter(y_validate, ocent_pred, \n",
    "            alpha=.2, color=\"green\", s=100, label=\"Model: LinearRegression-only centroids\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "plt.xlim(-.75, .75)\n",
    "plt.ylim(-.75, .75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "**Take aways from Validate**     \n",
    "None of these beat baseline. Possibly due to how feature selection works in the algorithm\n",
    "- tried reducing outliers\n",
    "- tried stratify on fips\n",
    "- reduced # features in models\n",
    "\n",
    "**Next Step**     \n",
    "- redo import of dataset to create feature that is \"extras\" garage, pool, fireplace, spa, shed, etc\n",
    "- isolate by county\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**None of the models beat the baseline during validate**      \n",
    "\n",
    "Conducting test on best perfoming from validate run:\n",
    "- Linear Regression on all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df for scaled test\n",
    "Xtests_ALL = X_test_scaled.copy().drop(columns=['size_cluster', 'rooms_cluster', 'dollar_cluster', \n",
    "                                                  'loc_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tall_RMSE, tall_pred = model.linear_reg_vt(Xtrains_ALL, Xtests_ALL, y_train, y_test)\n",
    "tall_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg. Error = (Validate Error + Test Error) /2 - Average preformance of model works on unseen data\n",
    "model_error = round((vall_RMSE + tall_RMSE) / 2 , 6)\n",
    "print(f'The average error for our model is {model_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcuating % improvement\n",
    "# First: work out the difference (increase) between the two numbers you are comparing\n",
    "difference = (baseline - tall_RMSE)\n",
    "# Then: divide the increase by the original number and multiply the answer by 100\n",
    "percent_improve = round((difference / baseline) * 100, 2)\n",
    "print(f'The % improvement for our model is {percent_improve}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.axhline(label=\"No Error\")\n",
    "plt.scatter(y_test, tall_pred - y_test,\n",
    "            alpha=.3, color=\"blue\", s=100, label=\"Model: LinearRegression-ALL\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"y_validate\")\n",
    "plt.ylabel(\"Residual/Error: Predicted - Actual\")\n",
    "plt.title(\"Do the size of errors change as the actual value changes?\")\n",
    "plt.xlim(-.75, .75)\n",
    "plt.ylim(-.75, .75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a baseline from train mean that is the same shape as test\n",
    "rows_needed = y_test.shape[0]\n",
    "# create array of predictions of same size as y_train.logerror based on the mean\n",
    "ty_hat = np.full(rows_needed, np.mean(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs y_validate\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(y_test, ty_hat, alpha=.5, color=\"gray\", label='_nolegend_')\n",
    "#plt.annotate(\"Baseline: Predict Using Mean\", (-3, 3))\n",
    "plt.plot(y_test, y_test, alpha=.5, color=\"blue\", label='_nolegend_')\n",
    "#plt.annotate(\"The Ideal Line: Predicted = Actual\", (.5, 3.5), rotation=15.5)\n",
    "\n",
    "plt.scatter(y_test, tall_pred, \n",
    "            alpha=.5, color=\"orange\", s=100, label=\"Model: LinearRegression-ALL\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"Where are predictions more extreme? More modest?\")\n",
    "plt.xlim(-.75, .75)\n",
    "plt.ylim(-.75, .75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delivery Stage\n",
    "DELIVERABLES:\n",
    "- [Main_Notebook](xxxxxxx)\n",
    "- walk through of notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of findings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models tested "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top perfoming model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. remove additional outliers in lotsize? there is a large spread in this feature with min of 435 sqft and max of 2M sqft\n",
    "2. many \"extra\" features like pool, hottub, shed, fireplace, deck got dropped because more than 50% of values were null, instead replace null with 0 for no then create feature that sums the extras for an etras count feature\n",
    "3. domain research on heating system frequency in this area of country, instead of drop fill heating nulls with \"no heating system\" or \"central\"?\n",
    "4. A common factor in purchasing a home is the quality of the schools in the area, homes not in LA county may see an increase in sale price from Zestimate (increased error) due to percieved value of schools? The school rankings by county are not in this dataset but could be an influencing factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
